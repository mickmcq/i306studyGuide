{"title":"Distributions of Random Variables","markdown":{"yaml":{"title":"Distributions of Random Variables"},"headingText":"Recap Week 04","containsRefs":false,"markdown":"\n\n```{r, include=FALSE}\nknitr::opts_chunk$set(\n  message=FALSE\n)\n```\n\nWe did week 04 in one day, covering numerous probability basics and doing a few exercises in probability, mostly paper and pencil exercises. We saw three examples of continuous probability distributions: normal, uniform, and F. This week, we'll examine continuous distributions in some more detail.\n\n## Five distributions\nWe previously looked at the normal distribution. In this\nChapter of the textbook, we visit five distributions:\n\n- Normal distribution\n- Geometric distribution\n- Binomial distribution\n- Negative binomial distribution\n- Poisson distribution\n\nTo save time, we will follow the textbook instead of\nlecture notes.\n\nThe following picture illustrates the normal distribution. The\nmound-shaped curve represents the probability density\nfunction and the area between the curve and the horizontal\nline represents the value of the cumulative distribution\nfunction.\n\n```{r}\n#| engine = 'tikz',\n#| engine.opts=list(extra.preamble=c(\"\\\\usepackage{pgfplots,stix,pagecolor}\",\"\\\\pgfplotsset{compat=1.18}\")),\n#| echo=FALSE\n\\pgfmathdeclarefunction{gauss}{2}{%\n  \\pgfmathparse{1/(#2*sqrt(2*pi))*exp(-((x-#1)^2)/(2*#2^2))}%\n}\n\\begin{tikzpicture}\n% picture of normal distribution pdf\n\\begin{axis}[\n  no markers, domain=70:130, samples=100,\n  axis lines=left, xlabel=$x$, ylabel=$f(x)$,\n  every axis y label/.style={at=(current axis.above origin),anchor=south},\n  every axis x label/.style={at=(current axis.right of origin),anchor=west},\n  height=3.6cm, width=10.6cm,\n  xtick=\\empty, ytick=\\empty,\n  enlargelimits=false, clip=false, axis on top,\n  extra x ticks={100},\n  extra x tick style={\n    tick label style={\n      rotate=90,anchor=east\n    }\n  },\n  extra x tick labels={\\scriptsize avg test score $\\rightarrow$}\n  ]\n  \\addplot [fill=cyan!20, draw=none, domain=70:100] {gauss(100,8)} \\closedcycle\n    node [style={font=\\scriptsize},above,text width=1.5cm] at (axis cs:95,0.005)\n      {probability of getting avg score or less};\n\n  \\addplot [very thick,cyan!50!black] {gauss(100,8)};\n\\draw [yshift=-2.2cm, <->](axis cs:70,0) -- node\n[fill=white] {$P(x \\leqslant \\text{avg})$} (axis cs:100,0);\n\\end{axis}\n\\end{tikzpicture}\n```\n\nConsider a normally distributed nationwide test.\n\nThe total shaded area between the curve and the straight\nhorizontal line can be thought of as one hundred percent\nof that area. In the world of probability, we measure that\narea as 1. The curve is symmetrical, so measure all the\narea to the left of the highest point on the curve as 0.5.\nThat is half, or fifty percent, of the total area between\nthe curve and the horizontal line at the bottom. Instead\nof saying *area between the curve and the horizontal\nline at the bottom*, people usually say *the area\nunder the curve*.\n\nFor any value along the $x$-axis, the $y$-value on the\ncurve represents the value of the probability density\nfunction.\n\nThe area bounded by the vertical line between the $x$-axis\nand the corresponding $y$-value on the curve, though, is\nwhat we are usually interested in because that area\nrepresents probability.\n\n## Notation\n\n$N(\\mu,\\sigma)$ is said to characterize a normal\ndistribution. If we know the *parameters* $\\mu$, the mean,\nand $\\sigma$, the standard deviation, we have a complete\npicture of the normal distribution, namely the height of\nthe hump and its width.\n\n## R function to find probability\nThe `pnorm()` function takes a value of a normally distributed\nrandom variable and returns the probability of that\nvalue or less. The textbook gives an example of the SAT\nand ACT scores. For the SAT, the textbook claims that $\\mu = 1100$ and\n$\\sigma=200$ so we can say the SAT score $x\\sim\nN(1100,200)$ which is read as \"x has the normal\ndistribution with mean 1100 and standard deviation 200.\"\nSuppose you score 1100. What is the probability that\nsomeone will score lower than you?\n\n```{r}\npnorm(1100,mean=1100,sd=200)\n```\n\nThis returns a value of 0.5 or fifty percent. That's\nsomething we can tell without a computer, but for the\nnormal distribution, other values are difficult to\ncompute by hand or guess correctly. For instance,\n\n```{r}\npnorm(1400,mean=1100,sd=200)\n```\n\nreturns a value of 0.9331928, or that 93 percent of\nstudents get below this score.\n\nBecause all probabilities sum to 1, we can use this\ninformation to tell the probability of someone getting a\nhigher score, or the probability of getting a score\nbetween two scores by subtracting the smaller from the\nlarger.\n\nThe textbook gives another example as finding the\nprobability that a particular student scores at least\n1190:\n\n```{r}\n1 - pnorm(1190,mean=1100,sd=200)\n```\n\nwhich returns 32.64 percent. Note that we did not\nexplicitly calculate the $Z$-score that leads to this\nprobability. The $Z$-score is a way of standardizing so\nthat instead of (in this case) $x\\sim N(1100,200)$, we\ncalculate the probability of $Z\\sim N(0,1)$. Here, we\nstandardize by recognizing that $Z=(x-\\mu)/\\sigma$ or\n$(1190-1100)/200=0.45$ and then we can say\n\n```{r}\n1 - pnorm(0.45,mean=0,sd=1)\n```\n\nand we get the same answer as above, 32.64 percent.\n\n## Geometric distribution\nFirst we need Bernoulli random variables to understand\nthe Geometric distribution.\n\nIf $X$ is a random variable that takes value 1 with\nprobability of success $p$ and $0$ with probability\n$1 − p$, then $X$ is a Bernoulli random variable with\nmean and standard deviation $\\mu=p$ and\n$\\sigma=\\sqrt{p(1-p)}$. A Bernoulli random variable is a\nprocess with only two outcomes: success or failure.\nFlipping a coin and calling it is an example of\nBernoulli random variable.\n\nNow the question is \"What happens if you flip a coin or\nroll the dice or some other win/lose process many times\nin a row?\"\n\nThe geometric distribution describes how many times it\ntakes to obtain success in a series of Bernoulli trials.\n\nThe textbook (p. 145) gives an example where an\ninsurance company employee is looking for the first\nperson to meet a criteria where the probability of\nmeeting that criteria is 0.7 or seventy percent. We can\ncalculate the probability of 0 failures (the first\nperson, one failure (the second person), and so on,\nusing R:\n\n```{r}\na <- dgeom(x=0,prob=0.7) # the first person\nb <- dgeom(x=1,prob=0.7) # the second person\nc <- dgeom(x=2,prob=0.7) # the third person\nd <- dgeom(x=3,prob=0.7) # the fourth person\ne <- dgeom(x=4,prob=0.7) # the fifth person\n```\n\nand if we graph these numbers, we'll find they have the\nproperty of exponential decay.\n\n```{r}\nx<-c(a,b,c,d,e)\nplot(x)\n```\n\nThe textbook gives the following definition of the\ngeometric distribution.\n\nIf the probability of a success in one trial is $p$ and\nthe probability of a failure is $1 − p$, then the\nprobability of finding the first success in the $n$th\ntrial is given by $(1 − p)^{n−1}p$. The mean (i.e. expected\nvalue) and standard deviation of this wait\ntime are given by $μ = 1/p$, $σ = \\sqrt{(1 − p)/p^2}$.\n\n## Binomial distribution\nThe textbook says that the binomial distribution is used to describe the number\nof successes in a fixed number of trials. This is\ndifferent from the geometric distribution, which\ndescribed the number of trials we must wait before we\nobserve a success.\n\nSuppose the probability of a single trial being a\nsuccess is $p$. Then the probability of observing exactly\n$k$ successes in $n$ independent trials is given by\n\n$$\n\\binom{n}{k}p^k(1-p)^{n-k}\n$$\n\nand $\\mu=np$, $\\sigma=\\sqrt{np(1-p)}$\n\n### Example using R\n\nThe website [r-tutor.com](https://www.r-tutor.com/elementary-statistics/probability-distributions/binomial-distribution) gives the following problem\nas an example:\n\n#### Problem\n\nSuppose there are twelve multiple choice questions in an\nEnglish class quiz. Each question has five possible\nanswers, and only one of them is correct. Find the\nprobability of having four or fewer correct answers if a student attempts to answer every question at random.\n\n#### Solution\n\nSince only one out of five possible answers is correct, the probability of answering a question correctly by random is 1/5=0.2. We can find the probability of having exactly 4 correct answers by random attempts as follows.\n\n```{r}\ndbinom(4, size=12, prob=0.2)\n```\n\nwhich returns 0.1329.\n\nTo find the probability of having four or less correct\nanswers by random attempts, we apply the function dbinom\nwith $x = 0,\\ldots,4$.\n\n```{r}\ndbinom(0, size=12, prob=0.2) +\ndbinom(1, size=12, prob=0.2) +\ndbinom(2, size=12, prob=0.2) +\ndbinom(3, size=12, prob=0.2) +\ndbinom(4, size=12, prob=0.2)\n```\n\nwhich returns 0.9274.\n\nAlternatively, we can use the cumulative probability function for binomial distribution pbinom.\n\n```{r}\npbinom(4, size=12, prob=0.2)\n```\n\nwhich returns the same answer.\n\n#### Answer\n\nThe probability of four or fewer questions answered correctly by random in a twelve question multiple choice quiz is 92.7%.\n\n## Negative binomial distribution\nThis is a generalization of the geometric distribution,\ndefined in the textbook as follows.\n\nThe negative binomial distribution describes the probability of observing the $k$th success on the\n$n$th trial, where all trials are independent:\n\n$$\nP (\\text{the kth success on the nth trial}) =\n\\binom{n − 1}{k − 1} p^k(1 − p)^{n−k}\n$$\n\nThe value $p$ represents the probability that an\nindividual trial is a success.\n\n## Poisson distribution\nThe textbook defines the Poisson distribution as\nfollows.\n\nSuppose we are watching for events and the number of\nobserved events follows a Poisson distribution with\nrate $λ$. Then\n\n$$\nP (\\text{observe k events}) = \\frac{λ^ke^{−λ}}{k!}\n$$\n\nwhere $k$\nmay take a value 0, 1, 2, and so on, and $k!$ represents\n$k$-factorial, as described on page 150. The letter e ≈\n2.718 is the base of the natural logarithm. The mean and\nstandard deviation of this distribution are λ and √λ,\nrespectively.\n\nThe r-tutor website mentioned above offers the following\nexample of a Poisson distribution problem solved using R.\n\n#### Problem\n\nIf there are twelve cars crossing a bridge per minute on average, find the probability of having seventeen or more cars crossing the bridge in a particular minute.\n\n#### Solution\n\nThe probability of having sixteen or fewer cars crossing the bridge in a particular minute is given by the function ppois.\n\n```{r}\nppois(16, lambda=12)   # lower tail\n```\n\nwhich returns 0.89871\n\nHence the probability of having seventeen or more cars crossing the bridge in a minute is in the upper tail of the probability density function.\n\n```{r}\nppois(16, lambda=12, lower=FALSE)   # upper tail\n```\n\nwhich returns 0.10129\n\n#### Answer\n\nIf there are twelve cars crossing a bridge per minute on average, the probability of having seventeen or more cars crossing the bridge in a particular minute is 10.1%.\n\n","srcMarkdownNoYaml":"\n\n```{r, include=FALSE}\nknitr::opts_chunk$set(\n  message=FALSE\n)\n```\n\n## Recap Week 04\nWe did week 04 in one day, covering numerous probability basics and doing a few exercises in probability, mostly paper and pencil exercises. We saw three examples of continuous probability distributions: normal, uniform, and F. This week, we'll examine continuous distributions in some more detail.\n\n## Five distributions\nWe previously looked at the normal distribution. In this\nChapter of the textbook, we visit five distributions:\n\n- Normal distribution\n- Geometric distribution\n- Binomial distribution\n- Negative binomial distribution\n- Poisson distribution\n\nTo save time, we will follow the textbook instead of\nlecture notes.\n\nThe following picture illustrates the normal distribution. The\nmound-shaped curve represents the probability density\nfunction and the area between the curve and the horizontal\nline represents the value of the cumulative distribution\nfunction.\n\n```{r}\n#| engine = 'tikz',\n#| engine.opts=list(extra.preamble=c(\"\\\\usepackage{pgfplots,stix,pagecolor}\",\"\\\\pgfplotsset{compat=1.18}\")),\n#| echo=FALSE\n\\pgfmathdeclarefunction{gauss}{2}{%\n  \\pgfmathparse{1/(#2*sqrt(2*pi))*exp(-((x-#1)^2)/(2*#2^2))}%\n}\n\\begin{tikzpicture}\n% picture of normal distribution pdf\n\\begin{axis}[\n  no markers, domain=70:130, samples=100,\n  axis lines=left, xlabel=$x$, ylabel=$f(x)$,\n  every axis y label/.style={at=(current axis.above origin),anchor=south},\n  every axis x label/.style={at=(current axis.right of origin),anchor=west},\n  height=3.6cm, width=10.6cm,\n  xtick=\\empty, ytick=\\empty,\n  enlargelimits=false, clip=false, axis on top,\n  extra x ticks={100},\n  extra x tick style={\n    tick label style={\n      rotate=90,anchor=east\n    }\n  },\n  extra x tick labels={\\scriptsize avg test score $\\rightarrow$}\n  ]\n  \\addplot [fill=cyan!20, draw=none, domain=70:100] {gauss(100,8)} \\closedcycle\n    node [style={font=\\scriptsize},above,text width=1.5cm] at (axis cs:95,0.005)\n      {probability of getting avg score or less};\n\n  \\addplot [very thick,cyan!50!black] {gauss(100,8)};\n\\draw [yshift=-2.2cm, <->](axis cs:70,0) -- node\n[fill=white] {$P(x \\leqslant \\text{avg})$} (axis cs:100,0);\n\\end{axis}\n\\end{tikzpicture}\n```\n\nConsider a normally distributed nationwide test.\n\nThe total shaded area between the curve and the straight\nhorizontal line can be thought of as one hundred percent\nof that area. In the world of probability, we measure that\narea as 1. The curve is symmetrical, so measure all the\narea to the left of the highest point on the curve as 0.5.\nThat is half, or fifty percent, of the total area between\nthe curve and the horizontal line at the bottom. Instead\nof saying *area between the curve and the horizontal\nline at the bottom*, people usually say *the area\nunder the curve*.\n\nFor any value along the $x$-axis, the $y$-value on the\ncurve represents the value of the probability density\nfunction.\n\nThe area bounded by the vertical line between the $x$-axis\nand the corresponding $y$-value on the curve, though, is\nwhat we are usually interested in because that area\nrepresents probability.\n\n## Notation\n\n$N(\\mu,\\sigma)$ is said to characterize a normal\ndistribution. If we know the *parameters* $\\mu$, the mean,\nand $\\sigma$, the standard deviation, we have a complete\npicture of the normal distribution, namely the height of\nthe hump and its width.\n\n## R function to find probability\nThe `pnorm()` function takes a value of a normally distributed\nrandom variable and returns the probability of that\nvalue or less. The textbook gives an example of the SAT\nand ACT scores. For the SAT, the textbook claims that $\\mu = 1100$ and\n$\\sigma=200$ so we can say the SAT score $x\\sim\nN(1100,200)$ which is read as \"x has the normal\ndistribution with mean 1100 and standard deviation 200.\"\nSuppose you score 1100. What is the probability that\nsomeone will score lower than you?\n\n```{r}\npnorm(1100,mean=1100,sd=200)\n```\n\nThis returns a value of 0.5 or fifty percent. That's\nsomething we can tell without a computer, but for the\nnormal distribution, other values are difficult to\ncompute by hand or guess correctly. For instance,\n\n```{r}\npnorm(1400,mean=1100,sd=200)\n```\n\nreturns a value of 0.9331928, or that 93 percent of\nstudents get below this score.\n\nBecause all probabilities sum to 1, we can use this\ninformation to tell the probability of someone getting a\nhigher score, or the probability of getting a score\nbetween two scores by subtracting the smaller from the\nlarger.\n\nThe textbook gives another example as finding the\nprobability that a particular student scores at least\n1190:\n\n```{r}\n1 - pnorm(1190,mean=1100,sd=200)\n```\n\nwhich returns 32.64 percent. Note that we did not\nexplicitly calculate the $Z$-score that leads to this\nprobability. The $Z$-score is a way of standardizing so\nthat instead of (in this case) $x\\sim N(1100,200)$, we\ncalculate the probability of $Z\\sim N(0,1)$. Here, we\nstandardize by recognizing that $Z=(x-\\mu)/\\sigma$ or\n$(1190-1100)/200=0.45$ and then we can say\n\n```{r}\n1 - pnorm(0.45,mean=0,sd=1)\n```\n\nand we get the same answer as above, 32.64 percent.\n\n## Geometric distribution\nFirst we need Bernoulli random variables to understand\nthe Geometric distribution.\n\nIf $X$ is a random variable that takes value 1 with\nprobability of success $p$ and $0$ with probability\n$1 − p$, then $X$ is a Bernoulli random variable with\nmean and standard deviation $\\mu=p$ and\n$\\sigma=\\sqrt{p(1-p)}$. A Bernoulli random variable is a\nprocess with only two outcomes: success or failure.\nFlipping a coin and calling it is an example of\nBernoulli random variable.\n\nNow the question is \"What happens if you flip a coin or\nroll the dice or some other win/lose process many times\nin a row?\"\n\nThe geometric distribution describes how many times it\ntakes to obtain success in a series of Bernoulli trials.\n\nThe textbook (p. 145) gives an example where an\ninsurance company employee is looking for the first\nperson to meet a criteria where the probability of\nmeeting that criteria is 0.7 or seventy percent. We can\ncalculate the probability of 0 failures (the first\nperson, one failure (the second person), and so on,\nusing R:\n\n```{r}\na <- dgeom(x=0,prob=0.7) # the first person\nb <- dgeom(x=1,prob=0.7) # the second person\nc <- dgeom(x=2,prob=0.7) # the third person\nd <- dgeom(x=3,prob=0.7) # the fourth person\ne <- dgeom(x=4,prob=0.7) # the fifth person\n```\n\nand if we graph these numbers, we'll find they have the\nproperty of exponential decay.\n\n```{r}\nx<-c(a,b,c,d,e)\nplot(x)\n```\n\nThe textbook gives the following definition of the\ngeometric distribution.\n\nIf the probability of a success in one trial is $p$ and\nthe probability of a failure is $1 − p$, then the\nprobability of finding the first success in the $n$th\ntrial is given by $(1 − p)^{n−1}p$. The mean (i.e. expected\nvalue) and standard deviation of this wait\ntime are given by $μ = 1/p$, $σ = \\sqrt{(1 − p)/p^2}$.\n\n## Binomial distribution\nThe textbook says that the binomial distribution is used to describe the number\nof successes in a fixed number of trials. This is\ndifferent from the geometric distribution, which\ndescribed the number of trials we must wait before we\nobserve a success.\n\nSuppose the probability of a single trial being a\nsuccess is $p$. Then the probability of observing exactly\n$k$ successes in $n$ independent trials is given by\n\n$$\n\\binom{n}{k}p^k(1-p)^{n-k}\n$$\n\nand $\\mu=np$, $\\sigma=\\sqrt{np(1-p)}$\n\n### Example using R\n\nThe website [r-tutor.com](https://www.r-tutor.com/elementary-statistics/probability-distributions/binomial-distribution) gives the following problem\nas an example:\n\n#### Problem\n\nSuppose there are twelve multiple choice questions in an\nEnglish class quiz. Each question has five possible\nanswers, and only one of them is correct. Find the\nprobability of having four or fewer correct answers if a student attempts to answer every question at random.\n\n#### Solution\n\nSince only one out of five possible answers is correct, the probability of answering a question correctly by random is 1/5=0.2. We can find the probability of having exactly 4 correct answers by random attempts as follows.\n\n```{r}\ndbinom(4, size=12, prob=0.2)\n```\n\nwhich returns 0.1329.\n\nTo find the probability of having four or less correct\nanswers by random attempts, we apply the function dbinom\nwith $x = 0,\\ldots,4$.\n\n```{r}\ndbinom(0, size=12, prob=0.2) +\ndbinom(1, size=12, prob=0.2) +\ndbinom(2, size=12, prob=0.2) +\ndbinom(3, size=12, prob=0.2) +\ndbinom(4, size=12, prob=0.2)\n```\n\nwhich returns 0.9274.\n\nAlternatively, we can use the cumulative probability function for binomial distribution pbinom.\n\n```{r}\npbinom(4, size=12, prob=0.2)\n```\n\nwhich returns the same answer.\n\n#### Answer\n\nThe probability of four or fewer questions answered correctly by random in a twelve question multiple choice quiz is 92.7%.\n\n## Negative binomial distribution\nThis is a generalization of the geometric distribution,\ndefined in the textbook as follows.\n\nThe negative binomial distribution describes the probability of observing the $k$th success on the\n$n$th trial, where all trials are independent:\n\n$$\nP (\\text{the kth success on the nth trial}) =\n\\binom{n − 1}{k − 1} p^k(1 − p)^{n−k}\n$$\n\nThe value $p$ represents the probability that an\nindividual trial is a success.\n\n## Poisson distribution\nThe textbook defines the Poisson distribution as\nfollows.\n\nSuppose we are watching for events and the number of\nobserved events follows a Poisson distribution with\nrate $λ$. Then\n\n$$\nP (\\text{observe k events}) = \\frac{λ^ke^{−λ}}{k!}\n$$\n\nwhere $k$\nmay take a value 0, 1, 2, and so on, and $k!$ represents\n$k$-factorial, as described on page 150. The letter e ≈\n2.718 is the base of the natural logarithm. The mean and\nstandard deviation of this distribution are λ and √λ,\nrespectively.\n\nThe r-tutor website mentioned above offers the following\nexample of a Poisson distribution problem solved using R.\n\n#### Problem\n\nIf there are twelve cars crossing a bridge per minute on average, find the probability of having seventeen or more cars crossing the bridge in a particular minute.\n\n#### Solution\n\nThe probability of having sixteen or fewer cars crossing the bridge in a particular minute is given by the function ppois.\n\n```{r}\nppois(16, lambda=12)   # lower tail\n```\n\nwhich returns 0.89871\n\nHence the probability of having seventeen or more cars crossing the bridge in a minute is in the upper tail of the probability density function.\n\n```{r}\nppois(16, lambda=12, lower=FALSE)   # upper tail\n```\n\nwhich returns 0.10129\n\n#### Answer\n\nIf there are twelve cars crossing a bridge per minute on average, the probability of having seventeen or more cars crossing the bridge in a particular minute is 10.1%.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":{"text":"<style>\n#quarto-sidebar .menu-text {\n  display: flex;\n}\n#quarto-sidebar .chapter-number {\n  display: block;\n  width: 1.5rem;\n  text-align: right;\n}\n#quarto-sidebar .chapter-title {\n  display: block;\n  padding-left: 8px;\n  text-indent: -2px;\n  width: 100%;\n}\n</style>\n"},"output-file":"week05.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","bibliography":["master.bib"],"mainfont":"Tex Gyre Schola","monofont":"JetBrainsMono Nerd Font","mathfont":"Tex Gyre Schola Math","theme":"cosmo","title":"Distributions of Random Variables"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}