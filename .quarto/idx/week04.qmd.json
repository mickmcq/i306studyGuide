{"title":"Introduction to Probability","markdown":{"yaml":{"title":"Introduction to Probability"},"headingText":"Recap Week 03","containsRefs":false,"markdown":"\n\n```{r, include=FALSE}\nknitr::opts_chunk$set(\n  message=FALSE\n)\n```\n\n\nWe did some exercises, for which there are now solutions in the file `week03exercises-soln.qmd` and `week03exercises-soln.html`. You should examine and compare these two files.\n\nLast semester, for each student, we calculated the number of exercises successfully completed. Following is a stem and leaf diagram, as well as summary statistics.\n\n```{r}\nx<-scan(\"week03exercisesList.txt\")\nstem(x)\nsummary(x)\nsd(x)\n```\n\nYou can make a number of inferences from this information. First, we should generally expect the average student to be able to complete six exercises during class time. If you completed fewer, you may need extra work outside class. If you completed more, you probably need less time outside of class. We can also see that the mean has been dragged downward by the students who didn't turn anything in, so the median is a better measure of centrality.\n\nWe can compare the stem and leaf plot to the following histogram and see that the stem and leaf plot looks kind of like a histogram turned on its side, and with a bit more information, especially if we alter the scale, so that it's not compressed to two exercises per row.\n\n```{r}\nhist(x)\nstem(x,scale=2)\n```\n\nWe also talked about milestone 1, for which there are some hints in the previous chapter.\n\n### Name value pairs\nIt came to my attention that not everyone knows what a name value pair is or how to read it. The name is always on the left and the value is always on the right. Usually there is an equal sign in between, but it doesn't mean *equals*. Instead it means *gets*. So, for example, in ggplot, there are *aesthetics* `x` and `y`. You can say something like `x=bill_depth_mm` and `y=bill_length_mm`. You would read the first one as \"x gets bill depth in millimeters\". It would make no sense to say the reverse. Don't ever say `bill_depth_mm=x`. Instead, let `x` and `y` be the names that ggplot knows about, the x-axis and the y-axis, and `bill_depth_mm` and `bill_length_mm` be the values that we plug into `x` and `y`.\n\nSimilarly, I found out that not everyone knows what we mean by *local* and *remote*. The local machine is your laptop. It is the machine close to you. The remote machine is the machine that hosts RStudio Server, the machine you connect to when you access the URL for RStudio. When you work in RStudio on the RStudio server, your work gets saved to the remote machine. Then you have to download it to your local machine and upload it to the machine that hosts Canvas. There is no direct path between the two remote machines that host RStudio Server and Canvas.\n\n## Bayesian approach\nThere are two competing schools of thought about what probability is. The bayesian approach is that probability is quantified belief or reasonable expectation of the outcomes of events based on a state of knowledge. This approach is recently taught in graduate schools. We will not extensively study this approach, but I want you to know that it exists and is rising in academic popularity.\n\n## Frequentist approach\nOur textbook takes a *frequentist* approach to probability, one of the two main approaches to probability and the one usually taught in undergraduate courses in the USA. This approach models probability of an *outcome* as the number of times the outcome would occur if we observed the *random process* that produced it an infinite number of times. For example, if we flip a fair coin an infinite number of times, it comes up heads half the time, so the probability of heads is 0.5.\n\n## The law of large numbers\nThis law claims that, as more outcomes are observed, the proportion of outcomes converges to the probability of the outcome. For example, if we flip a fair coin a hundred times, the probability of heads coming up half the time is greater than if we only flip it ten times.\n\nThe textbook uses the examples of rolling fair dice and flipping fair coins. Gaston Sanchez gives the example of flipping a fair coin modeled in R.\n\n```{r}\n#. number of flips\nnum_flips <- 1000\n\n#. flips simulation\ncoin <- c('heads', 'tails')\nflips <- sample(coin, size = num_flips, replace = TRUE)\n\n#. number of heads and tails\nfreqs <- table(flips)\nfreqs\nheads_freq <- cumsum(flips == 'heads') / 1:num_flips\nplot(heads_freq,      # vector\n     type = 'l',      # line type\n     lwd = 2,         # width of line\n     col = 'tomato',  # color of line\n     las = 1,         # orientation of tick-mark labels\n     ylim = c(0, 1),  # range of y-axis\n     xlab = \"number of tosses\",    # x-axis label\n     ylab = \"relative frequency\")  # y-axis label\nabline(h = 0.5, col = 'gray50')\n```\n\n## Disjoint outcomes\nThese are outcomes that can not both happen. For example, in the fair coin flipping case, the outcome cannot be both heads and tails. But the sum of all the disjoint probabilities is always 1.\n\n## Probabilities when outcomes are not disjoint\nThe textbook uses playing cards to illustrate concepts like *cards that are neither diamonds nor face cards*. You have to familiarize yourself with playing cards to understand these examples. The textbook uses the following Venn diagram to illustrate the above example.\n\n![](fiVennDiagramFace+Diamonds.png)\n\n## General addition rule\nThe textbook gives a general rule for multiple outcomes, whether they are disjoint or not.\n\nIf *A* and *B* are any two events, disjoint or not, then the probability that at least one of them\nwill occur is\n\n$$\nP (A\\text{ or }B) = P (A) + P (B) − P (A\\text{ and }B)\n$$\n\nwhere $P (A\\text{ and }B)$ is the probability that both events occur.\n\n## Counting Permutations and Combinations\nPermutations can be thought of as lineups. For instance, suppose you have five people to put in a line. There are five people to choose from to be first in line, then four people remain to be second in line, and so on. You can count this up as $5 \\times 4 \\times 3 \\times 2 \\times 1 = 5!$ or five factorial. This holds true for as many objects as you wish to line up.\n\nCombinations can be thought of as committees. There is no order as in a lineup. You're either a member or you're not. Suppose you want to form a committee of five people from among twenty people. It doesn't matter what order they come in so you can't use the factorial method to count them. There is another method, which you can find described in detail in @Ash1993. The main result is that, to choose a committee of 5 from among 20 people, use\n\n$$\n\\binom{20}{5} = \\frac{20!}{5!(20-5)!}\n$$\n\nThis is read as *twenty choose 5*.\n\nKeep in mind that\n\n$$\n\\binom{n}{r}=\\binom{n}{n-r}\n$$\n\nand\n\n$$\n\\binom{n}{1}=n\n$$\n\nand\n\n$$\n\\binom{n}{n}={n}{0}=1\n$$\n\nThis last result is because $0!=1$ by definition.\n\n@Ash1993 gives the examples of finding and not finding the Queen of Spades ($Q_s$) in a poker hand. You can think of a poker hand as a committee of 5 cards drawn from 52, so the total number of poker hands is given by $\\binom{52}{5}$. Finding hands containing the $Q_s$ amounts to choosing a committee of size four (the remainder of the hand, from among 51 cards (the remainder of the deck. So there are $\\binom{51}{4}$ such hands.\n\n$$\nP(Q_s)=\\dfrac{\\binom{51}{4}}{\\binom{52}{5}}=\\frac{5}{52}\n$$\n\nKeep in mind when canceling in stacked fractions that\n\n$$\n\\dfrac{\\frac{a}{b}}{\\frac{c}{d}}=\\dfrac{a \\cdot d}{b \\cdot c}\n$$\n\n## Probability distributions\nA probability distribution is a list of the possible\noutcomes with corresponding probabilities that satisfies\nthree rules:\n\n1. The outcomes listed must be disjoint.\n2. Each probability must be between 0 and 1.\n3. The probabilities must total 1.\n\n## Probability distribution for two fair dice\n\nFrancis DiTraglia shows the following example of plotting the probability distribution for rolling two fair dice on his [website](https://ditraglia.com/Econ103Public/Rtutorials/Rtutorial4.html).\n\n```{r}\ntwo.dice <- function() {\n  dice <- sample(1:6, size = 2, replace = TRUE)\n  return(sum(dice))\n}\nsims <- replicate(1000, two.dice())\nplot(table(sims), xlab = 'Sum', ylab = 'Frequency', main = '100 Rolls of 2 Fair Dice')\n```\n\nWhy is 7 the most likely outcome?\n\n## Terms from set theory\nSet theory is a mathematical discipline that uses tools like Venn diagrams to describes sets of objects. We can think of outcomes from random processes as objects, too, with the following terms.\n\n- sample space: the set of all possible outcomes\n- event: a particular outcome\n- complement of an event: outcomes in the sample space outside a given event or events\n\nThe complement of event $A$ is denoted $A^c$, and $A^c$ represents all outcomes not in $A$. $A$ and $A^c$\nare mathematically related:\n\n$$\nP (A) + P (A^c) = 1, \\text{ i.e. } P (A) = 1 − P (A^c)\n$$\n\n## Independence\nJust as variables and observations can be independent, random processes can be independent,\ntoo. Two processes are *independent* if knowing the outcome of one provides no useful information\nabout the outcome of the other. For instance, flipping a coin and rolling a die are two independent\nprocesses---knowing the coin was heads does not help determine the outcome of a die roll. On the\nother hand, stock prices usually move up or down together, so they are not independent.\n\n## Multiplication rule for independent processes\nIf $A$ and $B$ represent events from two different and independent processes, then the probability\nthat both $A$ and $B$ occur can be calculated as the product of their separate probabilities:\n\n$$\nP (A\\text{ and }B) = P (A) × P (B)\n$$\n\nSimilarly, if there are $k$ events $A_1, \\ldots, A_k$ from $k$ independent processes, then the probability\nthey all occur is\n\n$$\nP (A_1) × P (A_2) × \\cdots × P (A_k)\n$$\n\n## Conditional probability\nThis is where probability gets interesting. Some things depend on other things! The textbook uses a contingency table of the `photos_classify` data frame, which you can download from OpenIntro Stats, to explore this concept.\n\n```{r}\nload(paste0(Sys.getenv(\"STATS_DATA_DIR\"),\"/photo_classify.rda\"))\nstr(photo_classify)\naddmargins(table(photo_classify))\n```\n\nWe can use the entries in the contingency table to make statements about probability.\n\n- probability that a fashion photo is correctly classified by ML: 197/309\n- probability that a given photo is about fashion when predicted by ML to be not: 112/1603\n\nMarginal probability is the probability in the margins of table (right column and bottom row), e.g., ML predicts fashion photo at all: 219/1822.\n\nJoint probability is the probabillity of two (or more) things being true, e.g., ML predicts fashion and truth is fashion: 197/1822.\nA joint probability would be any of the four interior cells divided by the lower right cell.\n\nConditional probability is the probability of some outcome given the condition of another outcome, such as the probability that ML predicts fashion when the photo is truly about fashion: 197/219.\n\nConditional probability is very important. It's useful to know the general formula for conditional probability.\nThe conditional probability of outcome $A$ given condition $B$ is computed as the following:\n\n$$\nP (A|B) = \\frac{P (A\\text{ and }B)}{P (B)}\n$$\n\n## General multiplication rule\nWe already saw a specific multiplication rule for independent events. But there is a more general rule, applicable whether independence is true or not.\nIf $A$ and $B$ represent two outcomes or events, then\n\n$$\nP (A\\text{ and }B) = P (A|B) × P (B)\n$$\n\nIt is useful to think of $A$ as the outcome of interest and $B$ as the condition.\n\n## Tree diagrams of probability\nThe textbook claims that tree diagrams aid our thinking about conditional probabilities. Luckily, law professor Harry Surden provides an example of a tree diagram of probabilities on his website.\n\n```{r}\n#.. R Conditional Probability Tree Diagram\n\n#.. The Rgraphviz graphing package must be installed to do this\nlibrary(Rgraphviz)\n\n#.. Change the three variables below to match your actual values\n#.. These are the values that you can change for your own probability tree\n#.. From these three values, other probabilities (e.g. prob(b)) will be calculated\n\n#.. Probability of a\na<-.01\n\n#.. Probability (b | a)\nbGivena<-.99\n\n#. Probability (b | ¬a)\nbGivenNota<-.10\n\n###################### Everything below here will be calculated\n\n#. Calculate the rest of the values based upon the 3 variables above\nnotbGivena<-1-bGivena\nnotA<-1-a\nnotbGivenNota<-1-bGivenNota\n\n#. Joint Probabilities of a and B, a and notb, nota and b, nota and notb\naANDb<-a*bGivena\naANDnotb<-a*notbGivena\nnotaANDb <- notA*bGivenNota\nnotaANDnotb <- notA*notbGivenNota\n\n#. Probability of B\nb<- aANDb + notaANDb\nnotB <- 1-b\n\n#. Bayes theorum - probabiliyt of A | B\n#. (a | b) = Prob (a AND b) / prob (b)\naGivenb <- aANDb / b\n\n#. These are the labels of the nodes on the graph\n#. To signify \"Not A\" - we use A' or A prime\n\nnode1<-\"P\"\nnode2<-\"A\"\nnode3<-\"A'\"\nnode4<-\"A&B\"\nnode5<-\"A&B'\"\nnode6<-\"A'&B\"\nnode7<-\"A'&B'\"\nnodeNames<-c(node1,node2,node3,node4, node5,node6, node7)\n\nrEG <- new(\"graphNEL\", nodes=nodeNames, edgemode=\"directed\")\n\n#. Draw the \"lines\" or \"branches\" of the probability Tree\nrEG <- addEdge(nodeNames[1], nodeNames[2], rEG, 1)\nrEG <- addEdge(nodeNames[1], nodeNames[3], rEG, 1)\nrEG <- addEdge(nodeNames[2], nodeNames[4], rEG, 1)\nrEG <- addEdge(nodeNames[2], nodeNames[5], rEG, 1)\nrEG <- addEdge(nodeNames[3], nodeNames[6], rEG, 1)\nrEG <- addEdge(nodeNames[3], nodeNames[7], rEG, 10)\n\neAttrs <- list()\n\nq<-edgeNames(rEG)\n\n#. Add the probability values to the the branch lines\n\neAttrs$label <- c(toString(a),toString(notA),\n toString(bGivena), toString(notbGivena),\n toString(bGivenNota), toString(notbGivenNota))\nnames(eAttrs$label) <- c(q[1],q[2], q[3], q[4], q[5], q[6])\nedgeAttrs<-eAttrs\n\n#. Set the color, etc, of the tree\nattributes<-list(node=list(label=\"foo\", fillcolor=\"lightgreen\", fontsize=\"15\"),\n edge=list(color=\"red\"),graph=list(rankdir=\"LR\"))\n\n#. Plot the probability tree using Rgraphvis\nplot(rEG, edgeAttrs=eAttrs, attrs=attributes)\nnodes(rEG)\nedges(rEG)\n\n#. Add the probability values to the leaves of A&B, A&B', A'&B, A'&B'\ntext(500,420,aANDb, cex=.8)\n\ntext(500,280,aANDnotb,cex=.8)\n\ntext(500,160,notaANDb,cex=.8)\n\ntext(500,30,notaANDnotb,cex=.8)\n\ntext(340,440,\"(B | A)\",cex=.8)\n\ntext(340,230,\"(B | A')\",cex=.8)\n\n#. Write a table in the lower left of the probablites of A and B\ntext(80,50,paste(\"P(A):\",a),cex=.9, col=\"darkgreen\")\ntext(80,20,paste(\"P(A'):\",notA),cex=.9, col=\"darkgreen\")\n\ntext(160,50,paste(\"P(B):\",round(b,digits=2)),cex=.9)\ntext(160,20,paste(\"P(B'):\",round(notB, 2)),cex=.9)\n\ntext(80,420,paste(\"P(A|B): \",round(aGivenb,digits=2)),cex=.9,col=\"blue\")\n```\n\nIt's pretty ugly because it was designed for a different width and height than I have allocated, but it gives the general idea.\n\n## Bayes' Theorem\nIt's the centerpiece of Bayesian statistics so it's a bit like a fish out of water in a frequentist course. It states, in words, that the posterior probability of an outcome $A$ given an outcome $B$ is the likelihood of the outcome $B$ times the prior probability of the outcome $A$ divided by the evidence of outcome $B$. More succinctly,\n\n$$\nP(A|B)=\\frac{P(B|A)P(A)}{P(B)}\n$$\n\nThe intuition is that we usually know *something* and shouldn't go into problem solving with no assumptions. An example of drug user testing given by Wikipedia is shown below graphically, where the test is ninety percent sensitive to a recipient being a drug user. The test is also eighty percent specific, meaning that it can detect that a non-user is a non-user eighty percent of the time.\n\n![](fiBayesExample.png)\n\nWhat does this tell us about drug testing? Even if someone tests positive, the probability that they are a drug user is only 19%! This assumes prior knowledge that five percent of the general population are users of the drug.\n\nIn Bayesian terms:\n\n$$\n\\frac{0.9 \\times 0.05}{0.9\\times 0.05 + 0.2\\times0.95}\n$$\nBy the way, this formulation uses the law of total probability in the denominator, expanding $P(B)$ into\n\n$$\nP(B|A)P(A)+P(B|\\neg A)P(\\neg A)\n$$\n\nwhere $\\neg A$ is the complement of $A$.\n\nThis is very important to know about because, for example, someone might *only* tell you that a test is ninety percent sensitive and eighty percent specific and leave out the Bayes rule result that says that, given that only five percent of the general population are drug users, there's a nineteen percent chance that testing positive indicates that you are a drug user. Again, Bayes' rule is very important when you have some prior knowledge. In this case, the prior knowledge is a study that says that five percent of the general population are users of this drug.\n\n## Sampling from a small population\nRecall that the population includes every object and is usually not practical to measure. For examples, every fish, every person, every thunderstorm are too many to represent. So we take a sample. A typical rule of thumb is that, if we can sample more than ten percent of the population, we regard it as a small population.\n\nThe textbook gives an example of being called on by the professor. The chance that you are called on in a class of 15 is 1/15. If the professor calls on three different people in succession, the chance that you are called on increases to 1/5:\n\n\\begin{align}\nP(\\neg\\text{3 in a row}) &=\\\\\n&=P(\\text{not picked first, second, third})\\\\\n&=\\frac{14}{15}\\times\\frac{13}{14}\\times\\frac{12}{13}\\\\\n&=\\frac{12}{15}\\\\\n\\end{align}\n\nand the complement of 12/15 is 1/5.\n\n## Random variables\nA process with a random numerical outcome is called a random variable. It's kind of like a stochastic function in that there is an input (the process) and output (the outcome number).\n\nA random variable is usually represented as a capital, italicized Latin letter, e.g., $X, Y, Z$. Specific outcomes are usually represented as a lowercase, italicized Latin letter with a subscript to denote which outcome, such as $x_1, x_2, x_3$. The probability that a random variable $X$ has a specific outcome $x_1$ is represented as $P(X=x_1)$.\n\nThe expectation of $X$ is the expected value of $X$, represented as $E(X)$. The expected value is typically the average, but not always. If there are $k$ possible outcomes, then\n\n$$\nE(X)=\\sum_{i=1}^kx_iP(X=x_i)\n$$\n\nThe Greek letter $\\sum$ (Sigma) denotes a sum of a series of numbers, indexed in this case by $i$. You can read it in English as the sum, going from $1$ to $k$, of the expressions to the right of the Sigma sign. In other words,\n\n$$\nx_1P(X=x_1)+x_2P(X=x_2)+\\cdots+x_kP(X=x_k)\n$$\n\nIt's the average as we usually understand it if each outcome is equally probable, in which case it's the sum of the outcomes divided by the number of outcomes.\n\nWriters often substitute $E(X)=\\mu$ which can be confusing because Greek letters are usually used as parameters, while Latin letters are usually used as specific realizations of those parameters.\n\nThe above assumes there are $k$ specific outcomes. We call this case a *discrete random variable*. It's also possible to do math with a *continuous random variable*. In other words, $k=\\infty$. However, that requires calculus so the textbook skips it for now.\n\n### Variability in random variables\nRecall that random variables are a kind of mapping between a process and specific numerical outcomes. Those specific outcomes differ. For example, the revenue of a store varies day by day, and we can say something about that variability.\n\nWe usually express it by two related concepts: variance (denoted by a lowercase sigma squared or $\\sigma^2$), and its square root, standard deviation (denoted by a lowercase sigma or $\\sigma$). You might wonder why we don't just choose one of these symbols. Most statisticians just use standard deviation, but to prove that it is an unbiased estimator of variance, we need to square it for mathematical reasons that are beyond the scope of this course.\n\nStandard deviation is expressed in the same units as the subject under consideration, whereas variance is expressed in squared units. So when I said at the beginning of this file that the standard deviation of your completed exercises was about 2.69, I meant that in terms of number of exercises, meaning that most of you were within 2.69 completed exercises either way of each other. In other words, if you had three or nine completed exercises, you were a kind of outlier.\n\n### Linear combinations of random variables\nWe can put random variables together. For example, your GPA is calculated from a set of grades that may differ. If you play fantasy sports, your score comes from many different players. A recommender system for music listening may make calculations based on many different songs you listened to.\n\nA linear combination of two random variables can be expressed as $aX+bY$, where $a$ and $b$ are fixed constants, for example, the number of credits applied to each class in your GPA portfolio. If you take four four credit classes, your GPA might be expressed as the linear combination\n\n$$\n4E(X_1)+4E(X_2)+4E(X_3)+4E(X_4)\n$$\n\nwhere $E(X_i)$ is a function of your grade, such as your grade mapped to a number and divided by the number of credits you're taking. (Of course, you are used to thinking of it as the average of the grades since most classes carry the same number of credits and your grades are mapped to numbers. But this formulation holds for all kinds of sets.)\n\n## Continuous distributions\nSo far, we've considered discrete distributions, where $k$ takes on one of a finite set of values. What about the continuous case? For example, temperature can theoretically take on an infinite number of values, even though we only have the tools for discrete measurements.\n\nThe most famous continuous distribution is the normal distribution.\nThis picture illustrates the normal distribution. The\nmound-shaped curve represents the probability density\nfunction and the area between the curve and the horizontal\nline represents the value of the cumulative distribution\nfunction.\n\n```{r, engine = 'tikz',engine.opts=list(extra.preamble=c(\"\\\\usepackage{pgfplots,stix,pagecolor}\",\"\\\\definecolor{qopage}{HTML}{0E2A35}\")),echo=FALSE}\n\\pgfmathdeclarefunction{gauss}{2}{%\n  \\pgfmathparse{1/(#2*sqrt(2*pi))*exp(-((x-#1)^2)/(2*#2^2))}%\n}\n\\begin{tikzpicture}\n% picture of normal distribution pdf\n\\begin{axis}[\n  no markers, domain=70:130, samples=100,\n  axis lines=left, xlabel=$x$, ylabel=$f(x)$,\n  every axis y label/.style={at=(current axis.above origin),anchor=south},\n  every axis x label/.style={at=(current axis.right of origin),anchor=west},\n  height=3.6cm, width=10.6cm,\n  xtick=\\empty, ytick=\\empty,\n  enlargelimits=false, clip=false, axis on top,\n  extra x ticks={100},\n  extra x tick style={\n    tick label style={\n      rotate=90,anchor=east\n    }\n  },\n  extra x tick labels={\\scriptsize avg test score $\\rightarrow$}\n  ]\n  \\addplot [fill=cyan!20, draw=none, domain=70:100] {gauss(100,8)} \\closedcycle\n    node [style={font=\\scriptsize},above,text width=1.5cm] at (axis cs:95,0.005)\n      {probability of getting avg score or less};\n\n  \\addplot [very thick,cyan!50!black] {gauss(100,8)};\n\\draw [yshift=-2.2cm, <->](axis cs:70,0) -- node\n[fill=white] {$P(x \\leqslant \\text{avg})$} (axis cs:100,0);\n\\end{axis}\n\\end{tikzpicture}\n```\n\nConsider a normally distributed nationwide test.\n\nThe total shaded area between the curve and the straight\nhorizontal line can be thought of as one hundred percent\nof that area. In the world of probability, we measure that\narea as 1. The curve is symmetrical, so measure all the\narea to the left of the highest point on the curve as 0.5.\nThat is half, or fifty percent, of the total area between\nthe curve and the horizontal line at the bottom. Instead\nof saying *area between the curve and the horizontal\nline at the bottom*, people usually say *the area\nunder the curve*.\n\nFor any value along the $x$-axis, the $y$-value on the\ncurve represents the value of the probability density\nfunction.\n\nThe area bounded by the vertical line between the $x$-axis\nand the corresponding $y$-value on the curve, though, is\nwhat we are usually interested in because that area\nrepresents probability.\n\nHere is a graph of the *size* of that area. It's called the\ncumulative distribution function (cdf).\n\n```{r, engine = 'tikz',engine.opts=list(extra.preamble=c(\"\\\\usepackage{pgfplots,stix,pagecolor}\",\"\\\\definecolor{qopage}{HTML}{0E2A35}\")),echo=FALSE}\n\\begin{tikzpicture}\n% picture of normal distribution cdf\n\\begin{axis}[\n  no markers, domain=-5:5, samples=100,\n  axis lines=left, xlabel=$x$, ylabel=$f(x)$,\n  every axis y label/.style={at={(0,1.0)},anchor=south},\n  every axis x label/.style={at={(1.0,0)},anchor=west},\n  height=7cm, width=7cm,\n  xtick=\\empty, ytick=\\empty,\n  enlargelimits=false, clip=false, axis on top,\n  extra x ticks={0.5},\n  extra y ticks={0},\n  extra x tick labels={$\\frac{1}{2}$},\n  extra y tick labels={$\\frac{1}{2}$}\n  ]\n  \\addplot[mark=none,very thick,smooth,cyan!50!black] {2/(1+e^(-x))-1};\n\\end{axis}\n\\end{tikzpicture}\n```\n\nThe above graph can be read as having an input and output\nthat correspond to the previous graph of the probability\ndensity function. As we move from right to left on the\n$x$-axis, the area that would be to the left of a given\npoint on the probability density function is the $y$-value\non this graph. For example, if we go half way across the\n$x$-axis of the probability density function, the area to\nits left is one half of the total area, so the $y$-value\non the cumulative distribution function graph is one half.\n\nThe shape of the cumulative distribution function is\ncalled a sigmoid curve. You can see how it gets this shape\nby looking again at the probability density function graph\nabove. As you move from left to right on that graph, the\narea under the curve increases very slowly, then more\nrapidly, then slowly again. The places where the area\ngrows more rapidly and then more slowly on the probability\ndensity function curve correspond to the s-shaped bends on\nthe cumulative distribution curve.\n\nAt the left side of the cumulative distribution curve, the\n$y$-value is zero meaning zero probability. When we reach\nthe right side of the cumulative distribution curve, the\n$y$-value is 1 or 100 percent of the probability.\n\nLet's get back to the example of a nationwide test. If we\nsay that students nationwide took an test that had a mean\nscore of 75 and that the score was normally distributed,\nwe're saying that the value on the $x$-axis in the center\nof the curve is 75. Moreover, we're saying that the area\nto the left of 75 is one half of the total area. We're\nsaying that the probability of a score less than 75 is 0.5\nor fifty percent. We're saying that half the students got\na score below 75 and half got a score above 75.\n\nThat is called the frequentist interpretation of\nprobability. In general, that interpretation says that\na probability of 0.5 is properly measured by saying that,\nif we could repeat the event enough times, we would find\nthe event happening half of those times.\n\nFurthermore, the frequentist interpretation of the normal\ndistribution is that, if we could collect enough data,\nsuch as administering the above test to thousands of\nstudents, we would see that the graph of the frequency of\ntheir scores would look more and more like the bell curve\nin the picture, where $x$ is a test score and $y$ is the\nnumber of students receiving that score.\n\nSuppose we have the same test and the same distribution\nbut that the mean score is 60. Then 60 is in the middle\nand half the students are on each side. That is easy to\nmeasure. But what if, in either case, we would like to\nknow the probability associated with scores that are not\nat that convenient midpoint?\n\nIt's hard to measure any other area under the normal curve\nexcept for $x$-values in the middle of the curve,\ncorresponding to one half of the area. Why is this?\n\nTo see why it's hard to measure the area corresponding to\nany value except the middle value, let's first consider\na different probability distribution, the uniform\ndistribution. Suppose I have a machine that can generate\nany number between 0 and 1 at random. Further, suppose\nthat any such number is just as likely as any other such\nnumber.\n\nHere's a graph of the the uniform distribution of numbers\ngenerated by the machine. The horizontal line is the\nprobability density function and the shaded area is the\ncumulative distribution function from 0 to 1/2. In other\nwords, the probability of the machine generating numbers\nfrom 0 to 1/2 is 1/2. The probability of generating\nnumbers from 0 to 1 is 1, the area of the entire\nrectangle.\n\n```{r, engine = 'tikz',engine.opts=list(extra.preamble=c(\"\\\\usepackage{pgfplots,stix,pagecolor}\",\"\\\\definecolor{qopage}{HTML}{0E2A35}\")),echo=FALSE}\n\\begin{tikzpicture}\n% picture of uniform distribution pdf\n\\begin{axis}[\n  no markers, domain=0:1, samples=100,\n  axis lines=left, xlabel=$x$, ylabel=$f(x)$,\n  every axis y label/.style={at={(0,1.0)},anchor=south},\n  every axis x label/.style={at={(1.0,0)},anchor=west},\n  height=4cm, width=7cm,\n  xtick=\\empty, ytick=\\empty,\n  enlargelimits=false, clip=false, axis on top,\n  extra x ticks={0.5},\n  extra y ticks={0},\n  extra x tick labels={$\\frac{1}{2}$},\n  extra y tick labels={$\\frac{1}{2}$}\n  ]\n  \\fill[color=cyan!20] (axis cs:0.0,0.8) rectangle (axis cs:0.5,1);\n  \\addplot[mark=none,very thick,smooth,cyan!50!black] {1};\n\\end{axis}\n\\end{tikzpicture}\n```\n\nIt's very easy to calculate any probability for this\ndistribution, in contrast to the normal distribution. The\nreason it is easy is that you can just use the formula for\nthe area of a rectangle, where area is base times side.\nThe probability of being in the entire rectangle is\n$1\\times1=1$, and the probability of being in the part\nfrom $x=0$ to $x=1/4$ is just $1\\times(1/4)=1/4$. The\ncumulative distribution function of the uniform\ndistribution is simpler than that of the normal\ndistribution because area is being added at the same rate\nas we move from left to right on the above graph.\nTherefore it is just a straight diagonal line from (0,1)\non the left to (1,1) on the right.\n\n```{r, engine = 'tikz',engine.opts=list(extra.preamble=c(\"\\\\usepackage{pgfplots,stix,pagecolor}\",\"\\\\definecolor{qopage}{HTML}{0E2A35}\")),echo=FALSE}\n\\begin{tikzpicture}\n% picture of uniform distribution cdf\n\\begin{axis}[\n  no markers, domain=0:1, samples=100,\n  axis lines=left, xlabel=$x$, ylabel=$f(x)$,\n  every axis y label/.style={at={(0,1.0)},anchor=south},\n  every axis x label/.style={at={(1.0,0)},anchor=west},\n  height=5cm, width=5cm,\n  xtick=\\empty, ytick=\\empty,\n  enlargelimits=false, clip=false, axis on top,\n  extra x ticks={0.5},\n  extra y ticks={0.5},\n  extra x tick labels={$\\frac{1}{2}$},\n  extra y tick labels={$\\frac{1}{2}$}\n  ]\n  \\addplot[mark=none,very thick,smooth,cyan!50!black] {x};\n\\end{axis}\n\\end{tikzpicture}\n```\n\nReading it is the same as reading the cumulative\ndistribution function for the normal distribution. For any\nvalue on the $x$-axis, say, 1/2, go up to the diagonal\nline and over to the value on the $y$-axis. In this case,\nthat value is 1/2. That is the area under the horizontal\nline in the probability density function graph from 0 to\n1/2 (the shaded area). For a rectangle, calculating area\nis trivial.\n\nCalculating the area of a curved region like the normal\ndistribution can be more difficult. If you've studied any\ncalculus, you know that there are techniques for\ncalculating the area under a curve. These techniques are\ncalled integration techniques. In the case of the normal\ndistribution the formula for the height of the curve at\nany point on the $x$-axis is\n\n\\begin{equation*}\n\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-(x-\\mu)^2/2\\sigma^2}\n\\end{equation*}\n\nand the area is the integral of that quantity from $-\\infty$ to $x$,\nwhich can be rewritten as\n\n\\begin{equation*}\n\\frac{1}{\\sqrt{2\\pi}}\\int^x_{-\\infty}e^{-t^2/2}dt\n =(1/2)\\left(1+\\text{erf}\\left(\\frac{x-\\mu}{\\sigma\\sqrt{2}}\\right)\\right)\n\\end{equation*}\n\nThe integral on the left is difficult to evaluate so\npeople use numerical approximation techniques to find the\nexpression on the right in the above equation. Those\ntechniques are so time-consuming that, rather than\nrecompute them every time they are needed, a very few\npeople used to write the results into a table and publish\nit and most people working with probability would just\nconsult the tables. Only in the past few decades have\ncalculators become available that can do the tedious\napproximations. Hence, most statistics books, written by\npeople who were educated decades ago, still teach you how\nto use such tables. There is some debate as to whether\nthere is educational value in using the tables vs using\ncalculators or smartphone apps or web-based tables or\napps.\n\n## The F distribution\nAnother distribution that we'll enounter later is called the F distribution. We'll calculate an F-statistic when we build linear regression models, but I just want you to know the general shape of it for now. The region marked $\\alpha$ corresponds inversely to the magnitude of the F statistic. In other words, a larger F statistic means a smaller $\\alpha$.\n\n```{r, engine = 'tikz',engine.opts=list(extra.preamble=c(\"\\\\usepackage{pgfplots,stix,pagecolor}\",\"\\\\definecolor{qopage}{HTML}{0E2A35}\")),echo=FALSE}\n\\pgfmathdeclarefunction{fdist}{4}{%\n  \\pgfmathparse{#4*(x^(0.5*#2-1))*((1+#2*x/#3)^(-0.5*#2-0.5*#3))}%\n}\n\\begin{tikzpicture}\n  \\tikzset{\n        every pin/.style={fill=yellow!50!white,rectangle,rounded corners=3pt,font=\\tiny},\n        small dot/.style={fill=black,circle,scale=0.3}\n    }\n\\begin{axis}[\n  no markers, domain=0:3.5, samples=200,\n  axis lines=left, xlabel={}, ylabel=\\phantom{y},\n  every axis y label/.style={at=(current axis.above origin),anchor=south},\n  every axis x label/.style={at=(current axis.right of origin),anchor=west},\n  height=4cm, width=9cm,\n  xtick=\\empty, ytick=\\empty,\n  enlargelimits=false, clip=false, axis on top,\n    extra x ticks={0,2.5},\n    extra x tick labels={\\scriptsize 0, \\scriptsize $F_{\\alpha}$}\n  ]\n  \\addplot [fill=cyan!30, draw=none, domain=2.5:3.5]\n  {fdist(2,4,3,9)} \\closedcycle node [style={font=\\scriptsize},above,text width=1.5cm] at (axis cs:0,0.008) {};\n   \\node[small dot,pin=80:{$\\alpha$}]  at (axis cs:2.8,0.06) {};\n  \\addplot [very thick,cyan!50!black] {fdist(2,4,3,9)};\n\\end{axis}\n\\end{tikzpicture}\n```\n\n","srcMarkdownNoYaml":"\n\n```{r, include=FALSE}\nknitr::opts_chunk$set(\n  message=FALSE\n)\n```\n\n## Recap Week 03\n\nWe did some exercises, for which there are now solutions in the file `week03exercises-soln.qmd` and `week03exercises-soln.html`. You should examine and compare these two files.\n\nLast semester, for each student, we calculated the number of exercises successfully completed. Following is a stem and leaf diagram, as well as summary statistics.\n\n```{r}\nx<-scan(\"week03exercisesList.txt\")\nstem(x)\nsummary(x)\nsd(x)\n```\n\nYou can make a number of inferences from this information. First, we should generally expect the average student to be able to complete six exercises during class time. If you completed fewer, you may need extra work outside class. If you completed more, you probably need less time outside of class. We can also see that the mean has been dragged downward by the students who didn't turn anything in, so the median is a better measure of centrality.\n\nWe can compare the stem and leaf plot to the following histogram and see that the stem and leaf plot looks kind of like a histogram turned on its side, and with a bit more information, especially if we alter the scale, so that it's not compressed to two exercises per row.\n\n```{r}\nhist(x)\nstem(x,scale=2)\n```\n\nWe also talked about milestone 1, for which there are some hints in the previous chapter.\n\n### Name value pairs\nIt came to my attention that not everyone knows what a name value pair is or how to read it. The name is always on the left and the value is always on the right. Usually there is an equal sign in between, but it doesn't mean *equals*. Instead it means *gets*. So, for example, in ggplot, there are *aesthetics* `x` and `y`. You can say something like `x=bill_depth_mm` and `y=bill_length_mm`. You would read the first one as \"x gets bill depth in millimeters\". It would make no sense to say the reverse. Don't ever say `bill_depth_mm=x`. Instead, let `x` and `y` be the names that ggplot knows about, the x-axis and the y-axis, and `bill_depth_mm` and `bill_length_mm` be the values that we plug into `x` and `y`.\n\nSimilarly, I found out that not everyone knows what we mean by *local* and *remote*. The local machine is your laptop. It is the machine close to you. The remote machine is the machine that hosts RStudio Server, the machine you connect to when you access the URL for RStudio. When you work in RStudio on the RStudio server, your work gets saved to the remote machine. Then you have to download it to your local machine and upload it to the machine that hosts Canvas. There is no direct path between the two remote machines that host RStudio Server and Canvas.\n\n## Bayesian approach\nThere are two competing schools of thought about what probability is. The bayesian approach is that probability is quantified belief or reasonable expectation of the outcomes of events based on a state of knowledge. This approach is recently taught in graduate schools. We will not extensively study this approach, but I want you to know that it exists and is rising in academic popularity.\n\n## Frequentist approach\nOur textbook takes a *frequentist* approach to probability, one of the two main approaches to probability and the one usually taught in undergraduate courses in the USA. This approach models probability of an *outcome* as the number of times the outcome would occur if we observed the *random process* that produced it an infinite number of times. For example, if we flip a fair coin an infinite number of times, it comes up heads half the time, so the probability of heads is 0.5.\n\n## The law of large numbers\nThis law claims that, as more outcomes are observed, the proportion of outcomes converges to the probability of the outcome. For example, if we flip a fair coin a hundred times, the probability of heads coming up half the time is greater than if we only flip it ten times.\n\nThe textbook uses the examples of rolling fair dice and flipping fair coins. Gaston Sanchez gives the example of flipping a fair coin modeled in R.\n\n```{r}\n#. number of flips\nnum_flips <- 1000\n\n#. flips simulation\ncoin <- c('heads', 'tails')\nflips <- sample(coin, size = num_flips, replace = TRUE)\n\n#. number of heads and tails\nfreqs <- table(flips)\nfreqs\nheads_freq <- cumsum(flips == 'heads') / 1:num_flips\nplot(heads_freq,      # vector\n     type = 'l',      # line type\n     lwd = 2,         # width of line\n     col = 'tomato',  # color of line\n     las = 1,         # orientation of tick-mark labels\n     ylim = c(0, 1),  # range of y-axis\n     xlab = \"number of tosses\",    # x-axis label\n     ylab = \"relative frequency\")  # y-axis label\nabline(h = 0.5, col = 'gray50')\n```\n\n## Disjoint outcomes\nThese are outcomes that can not both happen. For example, in the fair coin flipping case, the outcome cannot be both heads and tails. But the sum of all the disjoint probabilities is always 1.\n\n## Probabilities when outcomes are not disjoint\nThe textbook uses playing cards to illustrate concepts like *cards that are neither diamonds nor face cards*. You have to familiarize yourself with playing cards to understand these examples. The textbook uses the following Venn diagram to illustrate the above example.\n\n![](fiVennDiagramFace+Diamonds.png)\n\n## General addition rule\nThe textbook gives a general rule for multiple outcomes, whether they are disjoint or not.\n\nIf *A* and *B* are any two events, disjoint or not, then the probability that at least one of them\nwill occur is\n\n$$\nP (A\\text{ or }B) = P (A) + P (B) − P (A\\text{ and }B)\n$$\n\nwhere $P (A\\text{ and }B)$ is the probability that both events occur.\n\n## Counting Permutations and Combinations\nPermutations can be thought of as lineups. For instance, suppose you have five people to put in a line. There are five people to choose from to be first in line, then four people remain to be second in line, and so on. You can count this up as $5 \\times 4 \\times 3 \\times 2 \\times 1 = 5!$ or five factorial. This holds true for as many objects as you wish to line up.\n\nCombinations can be thought of as committees. There is no order as in a lineup. You're either a member or you're not. Suppose you want to form a committee of five people from among twenty people. It doesn't matter what order they come in so you can't use the factorial method to count them. There is another method, which you can find described in detail in @Ash1993. The main result is that, to choose a committee of 5 from among 20 people, use\n\n$$\n\\binom{20}{5} = \\frac{20!}{5!(20-5)!}\n$$\n\nThis is read as *twenty choose 5*.\n\nKeep in mind that\n\n$$\n\\binom{n}{r}=\\binom{n}{n-r}\n$$\n\nand\n\n$$\n\\binom{n}{1}=n\n$$\n\nand\n\n$$\n\\binom{n}{n}={n}{0}=1\n$$\n\nThis last result is because $0!=1$ by definition.\n\n@Ash1993 gives the examples of finding and not finding the Queen of Spades ($Q_s$) in a poker hand. You can think of a poker hand as a committee of 5 cards drawn from 52, so the total number of poker hands is given by $\\binom{52}{5}$. Finding hands containing the $Q_s$ amounts to choosing a committee of size four (the remainder of the hand, from among 51 cards (the remainder of the deck. So there are $\\binom{51}{4}$ such hands.\n\n$$\nP(Q_s)=\\dfrac{\\binom{51}{4}}{\\binom{52}{5}}=\\frac{5}{52}\n$$\n\nKeep in mind when canceling in stacked fractions that\n\n$$\n\\dfrac{\\frac{a}{b}}{\\frac{c}{d}}=\\dfrac{a \\cdot d}{b \\cdot c}\n$$\n\n## Probability distributions\nA probability distribution is a list of the possible\noutcomes with corresponding probabilities that satisfies\nthree rules:\n\n1. The outcomes listed must be disjoint.\n2. Each probability must be between 0 and 1.\n3. The probabilities must total 1.\n\n## Probability distribution for two fair dice\n\nFrancis DiTraglia shows the following example of plotting the probability distribution for rolling two fair dice on his [website](https://ditraglia.com/Econ103Public/Rtutorials/Rtutorial4.html).\n\n```{r}\ntwo.dice <- function() {\n  dice <- sample(1:6, size = 2, replace = TRUE)\n  return(sum(dice))\n}\nsims <- replicate(1000, two.dice())\nplot(table(sims), xlab = 'Sum', ylab = 'Frequency', main = '100 Rolls of 2 Fair Dice')\n```\n\nWhy is 7 the most likely outcome?\n\n## Terms from set theory\nSet theory is a mathematical discipline that uses tools like Venn diagrams to describes sets of objects. We can think of outcomes from random processes as objects, too, with the following terms.\n\n- sample space: the set of all possible outcomes\n- event: a particular outcome\n- complement of an event: outcomes in the sample space outside a given event or events\n\nThe complement of event $A$ is denoted $A^c$, and $A^c$ represents all outcomes not in $A$. $A$ and $A^c$\nare mathematically related:\n\n$$\nP (A) + P (A^c) = 1, \\text{ i.e. } P (A) = 1 − P (A^c)\n$$\n\n## Independence\nJust as variables and observations can be independent, random processes can be independent,\ntoo. Two processes are *independent* if knowing the outcome of one provides no useful information\nabout the outcome of the other. For instance, flipping a coin and rolling a die are two independent\nprocesses---knowing the coin was heads does not help determine the outcome of a die roll. On the\nother hand, stock prices usually move up or down together, so they are not independent.\n\n## Multiplication rule for independent processes\nIf $A$ and $B$ represent events from two different and independent processes, then the probability\nthat both $A$ and $B$ occur can be calculated as the product of their separate probabilities:\n\n$$\nP (A\\text{ and }B) = P (A) × P (B)\n$$\n\nSimilarly, if there are $k$ events $A_1, \\ldots, A_k$ from $k$ independent processes, then the probability\nthey all occur is\n\n$$\nP (A_1) × P (A_2) × \\cdots × P (A_k)\n$$\n\n## Conditional probability\nThis is where probability gets interesting. Some things depend on other things! The textbook uses a contingency table of the `photos_classify` data frame, which you can download from OpenIntro Stats, to explore this concept.\n\n```{r}\nload(paste0(Sys.getenv(\"STATS_DATA_DIR\"),\"/photo_classify.rda\"))\nstr(photo_classify)\naddmargins(table(photo_classify))\n```\n\nWe can use the entries in the contingency table to make statements about probability.\n\n- probability that a fashion photo is correctly classified by ML: 197/309\n- probability that a given photo is about fashion when predicted by ML to be not: 112/1603\n\nMarginal probability is the probability in the margins of table (right column and bottom row), e.g., ML predicts fashion photo at all: 219/1822.\n\nJoint probability is the probabillity of two (or more) things being true, e.g., ML predicts fashion and truth is fashion: 197/1822.\nA joint probability would be any of the four interior cells divided by the lower right cell.\n\nConditional probability is the probability of some outcome given the condition of another outcome, such as the probability that ML predicts fashion when the photo is truly about fashion: 197/219.\n\nConditional probability is very important. It's useful to know the general formula for conditional probability.\nThe conditional probability of outcome $A$ given condition $B$ is computed as the following:\n\n$$\nP (A|B) = \\frac{P (A\\text{ and }B)}{P (B)}\n$$\n\n## General multiplication rule\nWe already saw a specific multiplication rule for independent events. But there is a more general rule, applicable whether independence is true or not.\nIf $A$ and $B$ represent two outcomes or events, then\n\n$$\nP (A\\text{ and }B) = P (A|B) × P (B)\n$$\n\nIt is useful to think of $A$ as the outcome of interest and $B$ as the condition.\n\n## Tree diagrams of probability\nThe textbook claims that tree diagrams aid our thinking about conditional probabilities. Luckily, law professor Harry Surden provides an example of a tree diagram of probabilities on his website.\n\n```{r}\n#.. R Conditional Probability Tree Diagram\n\n#.. The Rgraphviz graphing package must be installed to do this\nlibrary(Rgraphviz)\n\n#.. Change the three variables below to match your actual values\n#.. These are the values that you can change for your own probability tree\n#.. From these three values, other probabilities (e.g. prob(b)) will be calculated\n\n#.. Probability of a\na<-.01\n\n#.. Probability (b | a)\nbGivena<-.99\n\n#. Probability (b | ¬a)\nbGivenNota<-.10\n\n###################### Everything below here will be calculated\n\n#. Calculate the rest of the values based upon the 3 variables above\nnotbGivena<-1-bGivena\nnotA<-1-a\nnotbGivenNota<-1-bGivenNota\n\n#. Joint Probabilities of a and B, a and notb, nota and b, nota and notb\naANDb<-a*bGivena\naANDnotb<-a*notbGivena\nnotaANDb <- notA*bGivenNota\nnotaANDnotb <- notA*notbGivenNota\n\n#. Probability of B\nb<- aANDb + notaANDb\nnotB <- 1-b\n\n#. Bayes theorum - probabiliyt of A | B\n#. (a | b) = Prob (a AND b) / prob (b)\naGivenb <- aANDb / b\n\n#. These are the labels of the nodes on the graph\n#. To signify \"Not A\" - we use A' or A prime\n\nnode1<-\"P\"\nnode2<-\"A\"\nnode3<-\"A'\"\nnode4<-\"A&B\"\nnode5<-\"A&B'\"\nnode6<-\"A'&B\"\nnode7<-\"A'&B'\"\nnodeNames<-c(node1,node2,node3,node4, node5,node6, node7)\n\nrEG <- new(\"graphNEL\", nodes=nodeNames, edgemode=\"directed\")\n\n#. Draw the \"lines\" or \"branches\" of the probability Tree\nrEG <- addEdge(nodeNames[1], nodeNames[2], rEG, 1)\nrEG <- addEdge(nodeNames[1], nodeNames[3], rEG, 1)\nrEG <- addEdge(nodeNames[2], nodeNames[4], rEG, 1)\nrEG <- addEdge(nodeNames[2], nodeNames[5], rEG, 1)\nrEG <- addEdge(nodeNames[3], nodeNames[6], rEG, 1)\nrEG <- addEdge(nodeNames[3], nodeNames[7], rEG, 10)\n\neAttrs <- list()\n\nq<-edgeNames(rEG)\n\n#. Add the probability values to the the branch lines\n\neAttrs$label <- c(toString(a),toString(notA),\n toString(bGivena), toString(notbGivena),\n toString(bGivenNota), toString(notbGivenNota))\nnames(eAttrs$label) <- c(q[1],q[2], q[3], q[4], q[5], q[6])\nedgeAttrs<-eAttrs\n\n#. Set the color, etc, of the tree\nattributes<-list(node=list(label=\"foo\", fillcolor=\"lightgreen\", fontsize=\"15\"),\n edge=list(color=\"red\"),graph=list(rankdir=\"LR\"))\n\n#. Plot the probability tree using Rgraphvis\nplot(rEG, edgeAttrs=eAttrs, attrs=attributes)\nnodes(rEG)\nedges(rEG)\n\n#. Add the probability values to the leaves of A&B, A&B', A'&B, A'&B'\ntext(500,420,aANDb, cex=.8)\n\ntext(500,280,aANDnotb,cex=.8)\n\ntext(500,160,notaANDb,cex=.8)\n\ntext(500,30,notaANDnotb,cex=.8)\n\ntext(340,440,\"(B | A)\",cex=.8)\n\ntext(340,230,\"(B | A')\",cex=.8)\n\n#. Write a table in the lower left of the probablites of A and B\ntext(80,50,paste(\"P(A):\",a),cex=.9, col=\"darkgreen\")\ntext(80,20,paste(\"P(A'):\",notA),cex=.9, col=\"darkgreen\")\n\ntext(160,50,paste(\"P(B):\",round(b,digits=2)),cex=.9)\ntext(160,20,paste(\"P(B'):\",round(notB, 2)),cex=.9)\n\ntext(80,420,paste(\"P(A|B): \",round(aGivenb,digits=2)),cex=.9,col=\"blue\")\n```\n\nIt's pretty ugly because it was designed for a different width and height than I have allocated, but it gives the general idea.\n\n## Bayes' Theorem\nIt's the centerpiece of Bayesian statistics so it's a bit like a fish out of water in a frequentist course. It states, in words, that the posterior probability of an outcome $A$ given an outcome $B$ is the likelihood of the outcome $B$ times the prior probability of the outcome $A$ divided by the evidence of outcome $B$. More succinctly,\n\n$$\nP(A|B)=\\frac{P(B|A)P(A)}{P(B)}\n$$\n\nThe intuition is that we usually know *something* and shouldn't go into problem solving with no assumptions. An example of drug user testing given by Wikipedia is shown below graphically, where the test is ninety percent sensitive to a recipient being a drug user. The test is also eighty percent specific, meaning that it can detect that a non-user is a non-user eighty percent of the time.\n\n![](fiBayesExample.png)\n\nWhat does this tell us about drug testing? Even if someone tests positive, the probability that they are a drug user is only 19%! This assumes prior knowledge that five percent of the general population are users of the drug.\n\nIn Bayesian terms:\n\n$$\n\\frac{0.9 \\times 0.05}{0.9\\times 0.05 + 0.2\\times0.95}\n$$\nBy the way, this formulation uses the law of total probability in the denominator, expanding $P(B)$ into\n\n$$\nP(B|A)P(A)+P(B|\\neg A)P(\\neg A)\n$$\n\nwhere $\\neg A$ is the complement of $A$.\n\nThis is very important to know about because, for example, someone might *only* tell you that a test is ninety percent sensitive and eighty percent specific and leave out the Bayes rule result that says that, given that only five percent of the general population are drug users, there's a nineteen percent chance that testing positive indicates that you are a drug user. Again, Bayes' rule is very important when you have some prior knowledge. In this case, the prior knowledge is a study that says that five percent of the general population are users of this drug.\n\n## Sampling from a small population\nRecall that the population includes every object and is usually not practical to measure. For examples, every fish, every person, every thunderstorm are too many to represent. So we take a sample. A typical rule of thumb is that, if we can sample more than ten percent of the population, we regard it as a small population.\n\nThe textbook gives an example of being called on by the professor. The chance that you are called on in a class of 15 is 1/15. If the professor calls on three different people in succession, the chance that you are called on increases to 1/5:\n\n\\begin{align}\nP(\\neg\\text{3 in a row}) &=\\\\\n&=P(\\text{not picked first, second, third})\\\\\n&=\\frac{14}{15}\\times\\frac{13}{14}\\times\\frac{12}{13}\\\\\n&=\\frac{12}{15}\\\\\n\\end{align}\n\nand the complement of 12/15 is 1/5.\n\n## Random variables\nA process with a random numerical outcome is called a random variable. It's kind of like a stochastic function in that there is an input (the process) and output (the outcome number).\n\nA random variable is usually represented as a capital, italicized Latin letter, e.g., $X, Y, Z$. Specific outcomes are usually represented as a lowercase, italicized Latin letter with a subscript to denote which outcome, such as $x_1, x_2, x_3$. The probability that a random variable $X$ has a specific outcome $x_1$ is represented as $P(X=x_1)$.\n\nThe expectation of $X$ is the expected value of $X$, represented as $E(X)$. The expected value is typically the average, but not always. If there are $k$ possible outcomes, then\n\n$$\nE(X)=\\sum_{i=1}^kx_iP(X=x_i)\n$$\n\nThe Greek letter $\\sum$ (Sigma) denotes a sum of a series of numbers, indexed in this case by $i$. You can read it in English as the sum, going from $1$ to $k$, of the expressions to the right of the Sigma sign. In other words,\n\n$$\nx_1P(X=x_1)+x_2P(X=x_2)+\\cdots+x_kP(X=x_k)\n$$\n\nIt's the average as we usually understand it if each outcome is equally probable, in which case it's the sum of the outcomes divided by the number of outcomes.\n\nWriters often substitute $E(X)=\\mu$ which can be confusing because Greek letters are usually used as parameters, while Latin letters are usually used as specific realizations of those parameters.\n\nThe above assumes there are $k$ specific outcomes. We call this case a *discrete random variable*. It's also possible to do math with a *continuous random variable*. In other words, $k=\\infty$. However, that requires calculus so the textbook skips it for now.\n\n### Variability in random variables\nRecall that random variables are a kind of mapping between a process and specific numerical outcomes. Those specific outcomes differ. For example, the revenue of a store varies day by day, and we can say something about that variability.\n\nWe usually express it by two related concepts: variance (denoted by a lowercase sigma squared or $\\sigma^2$), and its square root, standard deviation (denoted by a lowercase sigma or $\\sigma$). You might wonder why we don't just choose one of these symbols. Most statisticians just use standard deviation, but to prove that it is an unbiased estimator of variance, we need to square it for mathematical reasons that are beyond the scope of this course.\n\nStandard deviation is expressed in the same units as the subject under consideration, whereas variance is expressed in squared units. So when I said at the beginning of this file that the standard deviation of your completed exercises was about 2.69, I meant that in terms of number of exercises, meaning that most of you were within 2.69 completed exercises either way of each other. In other words, if you had three or nine completed exercises, you were a kind of outlier.\n\n### Linear combinations of random variables\nWe can put random variables together. For example, your GPA is calculated from a set of grades that may differ. If you play fantasy sports, your score comes from many different players. A recommender system for music listening may make calculations based on many different songs you listened to.\n\nA linear combination of two random variables can be expressed as $aX+bY$, where $a$ and $b$ are fixed constants, for example, the number of credits applied to each class in your GPA portfolio. If you take four four credit classes, your GPA might be expressed as the linear combination\n\n$$\n4E(X_1)+4E(X_2)+4E(X_3)+4E(X_4)\n$$\n\nwhere $E(X_i)$ is a function of your grade, such as your grade mapped to a number and divided by the number of credits you're taking. (Of course, you are used to thinking of it as the average of the grades since most classes carry the same number of credits and your grades are mapped to numbers. But this formulation holds for all kinds of sets.)\n\n## Continuous distributions\nSo far, we've considered discrete distributions, where $k$ takes on one of a finite set of values. What about the continuous case? For example, temperature can theoretically take on an infinite number of values, even though we only have the tools for discrete measurements.\n\nThe most famous continuous distribution is the normal distribution.\nThis picture illustrates the normal distribution. The\nmound-shaped curve represents the probability density\nfunction and the area between the curve and the horizontal\nline represents the value of the cumulative distribution\nfunction.\n\n```{r, engine = 'tikz',engine.opts=list(extra.preamble=c(\"\\\\usepackage{pgfplots,stix,pagecolor}\",\"\\\\definecolor{qopage}{HTML}{0E2A35}\")),echo=FALSE}\n\\pgfmathdeclarefunction{gauss}{2}{%\n  \\pgfmathparse{1/(#2*sqrt(2*pi))*exp(-((x-#1)^2)/(2*#2^2))}%\n}\n\\begin{tikzpicture}\n% picture of normal distribution pdf\n\\begin{axis}[\n  no markers, domain=70:130, samples=100,\n  axis lines=left, xlabel=$x$, ylabel=$f(x)$,\n  every axis y label/.style={at=(current axis.above origin),anchor=south},\n  every axis x label/.style={at=(current axis.right of origin),anchor=west},\n  height=3.6cm, width=10.6cm,\n  xtick=\\empty, ytick=\\empty,\n  enlargelimits=false, clip=false, axis on top,\n  extra x ticks={100},\n  extra x tick style={\n    tick label style={\n      rotate=90,anchor=east\n    }\n  },\n  extra x tick labels={\\scriptsize avg test score $\\rightarrow$}\n  ]\n  \\addplot [fill=cyan!20, draw=none, domain=70:100] {gauss(100,8)} \\closedcycle\n    node [style={font=\\scriptsize},above,text width=1.5cm] at (axis cs:95,0.005)\n      {probability of getting avg score or less};\n\n  \\addplot [very thick,cyan!50!black] {gauss(100,8)};\n\\draw [yshift=-2.2cm, <->](axis cs:70,0) -- node\n[fill=white] {$P(x \\leqslant \\text{avg})$} (axis cs:100,0);\n\\end{axis}\n\\end{tikzpicture}\n```\n\nConsider a normally distributed nationwide test.\n\nThe total shaded area between the curve and the straight\nhorizontal line can be thought of as one hundred percent\nof that area. In the world of probability, we measure that\narea as 1. The curve is symmetrical, so measure all the\narea to the left of the highest point on the curve as 0.5.\nThat is half, or fifty percent, of the total area between\nthe curve and the horizontal line at the bottom. Instead\nof saying *area between the curve and the horizontal\nline at the bottom*, people usually say *the area\nunder the curve*.\n\nFor any value along the $x$-axis, the $y$-value on the\ncurve represents the value of the probability density\nfunction.\n\nThe area bounded by the vertical line between the $x$-axis\nand the corresponding $y$-value on the curve, though, is\nwhat we are usually interested in because that area\nrepresents probability.\n\nHere is a graph of the *size* of that area. It's called the\ncumulative distribution function (cdf).\n\n```{r, engine = 'tikz',engine.opts=list(extra.preamble=c(\"\\\\usepackage{pgfplots,stix,pagecolor}\",\"\\\\definecolor{qopage}{HTML}{0E2A35}\")),echo=FALSE}\n\\begin{tikzpicture}\n% picture of normal distribution cdf\n\\begin{axis}[\n  no markers, domain=-5:5, samples=100,\n  axis lines=left, xlabel=$x$, ylabel=$f(x)$,\n  every axis y label/.style={at={(0,1.0)},anchor=south},\n  every axis x label/.style={at={(1.0,0)},anchor=west},\n  height=7cm, width=7cm,\n  xtick=\\empty, ytick=\\empty,\n  enlargelimits=false, clip=false, axis on top,\n  extra x ticks={0.5},\n  extra y ticks={0},\n  extra x tick labels={$\\frac{1}{2}$},\n  extra y tick labels={$\\frac{1}{2}$}\n  ]\n  \\addplot[mark=none,very thick,smooth,cyan!50!black] {2/(1+e^(-x))-1};\n\\end{axis}\n\\end{tikzpicture}\n```\n\nThe above graph can be read as having an input and output\nthat correspond to the previous graph of the probability\ndensity function. As we move from right to left on the\n$x$-axis, the area that would be to the left of a given\npoint on the probability density function is the $y$-value\non this graph. For example, if we go half way across the\n$x$-axis of the probability density function, the area to\nits left is one half of the total area, so the $y$-value\non the cumulative distribution function graph is one half.\n\nThe shape of the cumulative distribution function is\ncalled a sigmoid curve. You can see how it gets this shape\nby looking again at the probability density function graph\nabove. As you move from left to right on that graph, the\narea under the curve increases very slowly, then more\nrapidly, then slowly again. The places where the area\ngrows more rapidly and then more slowly on the probability\ndensity function curve correspond to the s-shaped bends on\nthe cumulative distribution curve.\n\nAt the left side of the cumulative distribution curve, the\n$y$-value is zero meaning zero probability. When we reach\nthe right side of the cumulative distribution curve, the\n$y$-value is 1 or 100 percent of the probability.\n\nLet's get back to the example of a nationwide test. If we\nsay that students nationwide took an test that had a mean\nscore of 75 and that the score was normally distributed,\nwe're saying that the value on the $x$-axis in the center\nof the curve is 75. Moreover, we're saying that the area\nto the left of 75 is one half of the total area. We're\nsaying that the probability of a score less than 75 is 0.5\nor fifty percent. We're saying that half the students got\na score below 75 and half got a score above 75.\n\nThat is called the frequentist interpretation of\nprobability. In general, that interpretation says that\na probability of 0.5 is properly measured by saying that,\nif we could repeat the event enough times, we would find\nthe event happening half of those times.\n\nFurthermore, the frequentist interpretation of the normal\ndistribution is that, if we could collect enough data,\nsuch as administering the above test to thousands of\nstudents, we would see that the graph of the frequency of\ntheir scores would look more and more like the bell curve\nin the picture, where $x$ is a test score and $y$ is the\nnumber of students receiving that score.\n\nSuppose we have the same test and the same distribution\nbut that the mean score is 60. Then 60 is in the middle\nand half the students are on each side. That is easy to\nmeasure. But what if, in either case, we would like to\nknow the probability associated with scores that are not\nat that convenient midpoint?\n\nIt's hard to measure any other area under the normal curve\nexcept for $x$-values in the middle of the curve,\ncorresponding to one half of the area. Why is this?\n\nTo see why it's hard to measure the area corresponding to\nany value except the middle value, let's first consider\na different probability distribution, the uniform\ndistribution. Suppose I have a machine that can generate\nany number between 0 and 1 at random. Further, suppose\nthat any such number is just as likely as any other such\nnumber.\n\nHere's a graph of the the uniform distribution of numbers\ngenerated by the machine. The horizontal line is the\nprobability density function and the shaded area is the\ncumulative distribution function from 0 to 1/2. In other\nwords, the probability of the machine generating numbers\nfrom 0 to 1/2 is 1/2. The probability of generating\nnumbers from 0 to 1 is 1, the area of the entire\nrectangle.\n\n```{r, engine = 'tikz',engine.opts=list(extra.preamble=c(\"\\\\usepackage{pgfplots,stix,pagecolor}\",\"\\\\definecolor{qopage}{HTML}{0E2A35}\")),echo=FALSE}\n\\begin{tikzpicture}\n% picture of uniform distribution pdf\n\\begin{axis}[\n  no markers, domain=0:1, samples=100,\n  axis lines=left, xlabel=$x$, ylabel=$f(x)$,\n  every axis y label/.style={at={(0,1.0)},anchor=south},\n  every axis x label/.style={at={(1.0,0)},anchor=west},\n  height=4cm, width=7cm,\n  xtick=\\empty, ytick=\\empty,\n  enlargelimits=false, clip=false, axis on top,\n  extra x ticks={0.5},\n  extra y ticks={0},\n  extra x tick labels={$\\frac{1}{2}$},\n  extra y tick labels={$\\frac{1}{2}$}\n  ]\n  \\fill[color=cyan!20] (axis cs:0.0,0.8) rectangle (axis cs:0.5,1);\n  \\addplot[mark=none,very thick,smooth,cyan!50!black] {1};\n\\end{axis}\n\\end{tikzpicture}\n```\n\nIt's very easy to calculate any probability for this\ndistribution, in contrast to the normal distribution. The\nreason it is easy is that you can just use the formula for\nthe area of a rectangle, where area is base times side.\nThe probability of being in the entire rectangle is\n$1\\times1=1$, and the probability of being in the part\nfrom $x=0$ to $x=1/4$ is just $1\\times(1/4)=1/4$. The\ncumulative distribution function of the uniform\ndistribution is simpler than that of the normal\ndistribution because area is being added at the same rate\nas we move from left to right on the above graph.\nTherefore it is just a straight diagonal line from (0,1)\non the left to (1,1) on the right.\n\n```{r, engine = 'tikz',engine.opts=list(extra.preamble=c(\"\\\\usepackage{pgfplots,stix,pagecolor}\",\"\\\\definecolor{qopage}{HTML}{0E2A35}\")),echo=FALSE}\n\\begin{tikzpicture}\n% picture of uniform distribution cdf\n\\begin{axis}[\n  no markers, domain=0:1, samples=100,\n  axis lines=left, xlabel=$x$, ylabel=$f(x)$,\n  every axis y label/.style={at={(0,1.0)},anchor=south},\n  every axis x label/.style={at={(1.0,0)},anchor=west},\n  height=5cm, width=5cm,\n  xtick=\\empty, ytick=\\empty,\n  enlargelimits=false, clip=false, axis on top,\n  extra x ticks={0.5},\n  extra y ticks={0.5},\n  extra x tick labels={$\\frac{1}{2}$},\n  extra y tick labels={$\\frac{1}{2}$}\n  ]\n  \\addplot[mark=none,very thick,smooth,cyan!50!black] {x};\n\\end{axis}\n\\end{tikzpicture}\n```\n\nReading it is the same as reading the cumulative\ndistribution function for the normal distribution. For any\nvalue on the $x$-axis, say, 1/2, go up to the diagonal\nline and over to the value on the $y$-axis. In this case,\nthat value is 1/2. That is the area under the horizontal\nline in the probability density function graph from 0 to\n1/2 (the shaded area). For a rectangle, calculating area\nis trivial.\n\nCalculating the area of a curved region like the normal\ndistribution can be more difficult. If you've studied any\ncalculus, you know that there are techniques for\ncalculating the area under a curve. These techniques are\ncalled integration techniques. In the case of the normal\ndistribution the formula for the height of the curve at\nany point on the $x$-axis is\n\n\\begin{equation*}\n\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-(x-\\mu)^2/2\\sigma^2}\n\\end{equation*}\n\nand the area is the integral of that quantity from $-\\infty$ to $x$,\nwhich can be rewritten as\n\n\\begin{equation*}\n\\frac{1}{\\sqrt{2\\pi}}\\int^x_{-\\infty}e^{-t^2/2}dt\n =(1/2)\\left(1+\\text{erf}\\left(\\frac{x-\\mu}{\\sigma\\sqrt{2}}\\right)\\right)\n\\end{equation*}\n\nThe integral on the left is difficult to evaluate so\npeople use numerical approximation techniques to find the\nexpression on the right in the above equation. Those\ntechniques are so time-consuming that, rather than\nrecompute them every time they are needed, a very few\npeople used to write the results into a table and publish\nit and most people working with probability would just\nconsult the tables. Only in the past few decades have\ncalculators become available that can do the tedious\napproximations. Hence, most statistics books, written by\npeople who were educated decades ago, still teach you how\nto use such tables. There is some debate as to whether\nthere is educational value in using the tables vs using\ncalculators or smartphone apps or web-based tables or\napps.\n\n## The F distribution\nAnother distribution that we'll enounter later is called the F distribution. We'll calculate an F-statistic when we build linear regression models, but I just want you to know the general shape of it for now. The region marked $\\alpha$ corresponds inversely to the magnitude of the F statistic. In other words, a larger F statistic means a smaller $\\alpha$.\n\n```{r, engine = 'tikz',engine.opts=list(extra.preamble=c(\"\\\\usepackage{pgfplots,stix,pagecolor}\",\"\\\\definecolor{qopage}{HTML}{0E2A35}\")),echo=FALSE}\n\\pgfmathdeclarefunction{fdist}{4}{%\n  \\pgfmathparse{#4*(x^(0.5*#2-1))*((1+#2*x/#3)^(-0.5*#2-0.5*#3))}%\n}\n\\begin{tikzpicture}\n  \\tikzset{\n        every pin/.style={fill=yellow!50!white,rectangle,rounded corners=3pt,font=\\tiny},\n        small dot/.style={fill=black,circle,scale=0.3}\n    }\n\\begin{axis}[\n  no markers, domain=0:3.5, samples=200,\n  axis lines=left, xlabel={}, ylabel=\\phantom{y},\n  every axis y label/.style={at=(current axis.above origin),anchor=south},\n  every axis x label/.style={at=(current axis.right of origin),anchor=west},\n  height=4cm, width=9cm,\n  xtick=\\empty, ytick=\\empty,\n  enlargelimits=false, clip=false, axis on top,\n    extra x ticks={0,2.5},\n    extra x tick labels={\\scriptsize 0, \\scriptsize $F_{\\alpha}$}\n  ]\n  \\addplot [fill=cyan!30, draw=none, domain=2.5:3.5]\n  {fdist(2,4,3,9)} \\closedcycle node [style={font=\\scriptsize},above,text width=1.5cm] at (axis cs:0,0.008) {};\n   \\node[small dot,pin=80:{$\\alpha$}]  at (axis cs:2.8,0.06) {};\n  \\addplot [very thick,cyan!50!black] {fdist(2,4,3,9)};\n\\end{axis}\n\\end{tikzpicture}\n```\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":{"text":"<style>\n#quarto-sidebar .menu-text {\n  display: flex;\n}\n#quarto-sidebar .chapter-number {\n  display: block;\n  width: 1.5rem;\n  text-align: right;\n}\n#quarto-sidebar .chapter-title {\n  display: block;\n  padding-left: 8px;\n  text-indent: -2px;\n  width: 100%;\n}\n</style>\n"},"output-file":"week04.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","bibliography":["master.bib"],"mainfont":"Tex Gyre Schola","monofont":"JetBrainsMono Nerd Font","mathfont":"Tex Gyre Schola Math","theme":"cosmo","title":"Introduction to Probability"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}